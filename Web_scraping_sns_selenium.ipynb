{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web scraping names and details of stocks with max Gain and Loss using selenium webdriver\n",
    "\n",
    "We are scrapping the names of top ten and bottom 10 stocks from BSE website, and later the names of each stock is then fed to the twitter scraper.\n",
    "\n",
    "twitter scraper uses the query to scrape tweets related to the stock names, the time frame taken is past 7 months.\n",
    "\n",
    "We are saving the scraped tweets along with the information on username, time and a flag to identify the stock status\n",
    "\n",
    "stock staus 0 is a loser stock and 1 denotes its a gainer stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries for webscraping\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up browser config for web driver\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "driverPATH =  r'/home/alby/Downloads/chromedriver'\n",
    "browserBIN = '/usr/bin/vivaldi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up browser config for web driver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.binary_location = browserBIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33648/2275245732.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(driverPATH, options=options)\n"
     ]
    }
   ],
   "source": [
    "##setting up browser config for web driver\n",
    "driver = webdriver.Chrome(driverPATH, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accessing url for the site with stock info\n",
    "\n",
    "url=\"https://www.bseindia.com/markets.html\"\n",
    "driver.get(url)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accessing the urls of top 10 gainers and losers\n",
    "\n",
    "gain_table=driver.find_elements(By.XPATH,\"//tbody[@class='ng-scope'and @ng-repeat='G in GainersAndLoosers.Table track by G.scrip_cd']\")\n",
    "links_gain=[]\n",
    "for j in gain_table:\n",
    "    time.sleep(2)\n",
    "\n",
    "    link_tag=j.find_element(By.TAG_NAME,\"a\")\n",
    "    links_gain.append(link_tag.get_attribute('href'))\n",
    "\n",
    "#clicking to access the losers column\n",
    "\n",
    "\n",
    "links_loss=[]\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "loss=driver.find_element(By.XPATH,'//*[@id=\"idLosers\"]')\n",
    "loss.click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "#accessing the table\n",
    "\n",
    "loss_table=driver.find_elements(By.XPATH,\"//tbody[@class='ng-scope'and @ng-repeat='L in GainersAndLoosers1.Table track by L.scrip_cd']\")\n",
    "\n",
    "\n",
    "for l in loss_table:\n",
    "\n",
    "    tag=l.find_element(By.TAG_NAME,\"a\")\n",
    "    links_loss.append(tag.get_attribute('href'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The url for each stocks is scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting names of top stocks in gain and loss\n",
    "gain_stocks=[]\n",
    "loss_stocks=[]\n",
    "for name in links_gain:\n",
    "    gain_stocks.append(name.split(\"/\")[4].replace(\"-\",\" \").replace(\"ltd\",\" \").strip())\n",
    "\n",
    "#loss stocks\n",
    "for names in links_loss:\n",
    "    loss_stocks.append(names.split(\"/\")[4].replace(\"-\",\" \").replace(\"ltd\",\" \").strip())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 10 stocks are saved in gain stocks and the bottom 10 loss_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33648/3767384733.py:13: FutureWarning: username is deprecated, use user.username instead\n",
      "  tweets.append([tweet.date, tweet.username, tweet.content,gainer,1])\n"
     ]
    }
   ],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "###Sns scraping-Twitter for tweets on stocks\n",
    "tweets = []\n",
    "\n",
    "\n",
    "\n",
    "for gainer in gain_stocks:\n",
    "\n",
    "    query = str(gainer)  + \" lang:en until:2022-07-12 since:2022-06-01\"\n",
    "    \n",
    "    for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "        tweets.append([tweet.date, tweet.username, tweet.content,gainer,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33648/1943940824.py:14: FutureWarning: username is deprecated, use user.username instead\n",
      "  ltweets.append([twee.date, twee.username, twee.content,loser,0])\n"
     ]
    }
   ],
   "source": [
    "#Scraping tweets for bottom ten stocks\n",
    "\n",
    "ltweets=[]\n",
    "\n",
    "\n",
    "for loser in loss_stocks:\n",
    "\n",
    "    query = str(loser)+ \" lang:en until:2022-07-12 since:2022-06-01\"\n",
    "\n",
    "    for twee in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "    \n",
    "    # print(vars(tweet))\n",
    "    # break\n",
    "            ltweets.append([twee.date, twee.username, twee.content,loser,0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18212"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking total number of tweets\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the dataframe for scraped data\n",
    "\n",
    "df1 = pd.DataFrame(tweets, columns=['Date', 'User', 'Tweet','company','Stock_status'])\n",
    "\n",
    "df2 = pd.DataFrame(ltweets, columns=['Date', 'User', 'Tweet','company','Stock_status'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging the dataframe\n",
    "df=pd.concat([df1,df2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving as csv\n",
    "df.to_csv('Stocks_twitter.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "789fb34462f482e38fdbd0940fbb6e5b0fbd4a5284d680984504ae0721c812bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
